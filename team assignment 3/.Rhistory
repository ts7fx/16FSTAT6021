var(3)
var(c(1,2))
# Get success/failure data, associated with a bi-modal predictor.
failures = cbind(0, rnorm(100, mean=-5))
successes = cbind(1, rnorm(100, mean=5))
View(failures)
failures = cbind(0, rnorm(100, mean=-5))
View(failures)
View(failures)
successes = cbind(1, rnorm(100, mean=5))
View(successes)
data = as.data.frame(rbind(successes, failures))
View(data)
names(data) = c("y", "x")
View(data)
?par
par(mfrow=c(1,2))
hist(data[data$y==0,2], main="Failures", xlab="x-value")
View(data)
hist(data[data$y==1,2], main="Successes", xlab="x-value")
par(mfrow=c(1,1))
par(mfrow=c(1,2))
hist(data[data$y==0,2], main="Failures", xlab="x-value")
hist(data[data$y==1,2], main="Successes", xlab="x-value")
par(mfrow=c(1,1))
hist(data[data$y==0,2], main="Failures", xlab="x-value")
hist(data[data$y==1,2], main="Successes", xlab="x-value")
?par
mfrow?
?mfrow
par(mfrow=c(1,10))
par(mfrow=c(1,3))
hist(data[data$y==0,2], main="Failures", xlab="x-value")
hist(data[data$y==1,2], main="Successes", xlab="x-value")
par(mfrow=c(2,2))
hist(data[data$y==0,2], main="Failures", xlab="x-value")
hist(data[data$y==1,2], main="Successes", xlab="x-value")
hist(data[data$y==0,2], main="Failures", xlab="x-value")
hist(data[data$y==1,2], main="Successes", xlab="x-value")
par(mfrow=c(1,1))
# A linear model of success/failure is fine, but linear regression isn't bounded appropriately, as we show below.
bad.idea.fit = lm(y ~ x, data = data)
summary(bad.idea.fit)
View(data)
new.data = as.data.frame(rbind(cbind(NA, rnorm(10, mean=-20)), cbind(NA, rnorm(10, mean=20))))
View(new.data)
names(new.data) = c("y", "x")
predict(bad.idea.fit, newdata = new.data, type="response")
View(new.data)
?seq
x = seq(-10, 10, 0.1)
probability = 1 / (1 + exp(-x))
plot(x, probability, type="l", main="Logistic Function for Regression", xlab="Regressors", ylab="Probability")
x
-x
probability = 1 / (1 + exp(x))
plot(x, probability, type="l", main="Logistic Function for Regression", xlab="Regressors", ylab="Probability")
probability = 1 / (1 + exp(-x))
plot(x, probability, type="l", main="Logistic Function for Regression", xlab="Regressors", ylab="Probability")
good.idea.fit = glm(y ~ x, data = data, family="binomial")
summary(good.idea.fit)
predict(good.idea.fit, newdata = new.data, type="response")
?exp
x = seq(10, -10, 0.1)
probability = 1 / (1 + exp(x))
x = seq(-10, 10, 0.1)
probability = 1 / (1 + exp(-x))
plot(x, probability, type="l", main="Logistic Function for Regression", xlab="Regressors", ylab="Probability")
probability
exp(-10)
?log
log(-10)
log(-10,base=e)
log(-10,base=2.718)
exp(1)
log(-10,base=exp(1))
log(10,base=exp(1))
exp(2)
exp(1)
setwd("~/Documents/16FSTAT6021/team assignment 3")
d1<- read.csv("teamassign03data01.csv")
d2<- read.csv("teamassign03data02.csv")
View(d1)
View(d2)
?sample
data01.sample <- sample(data01, 100)
data01<- read.csv("teamassign03data01.csv")
data02<- read.csv("teamassign03data02.csv")
data01.sample <- sample(data01, 100)
data01.sample <- sample(data01, size=100)
data01.sample <- data01[sample(c(1:nrow(data01)),100), ]
View(data01.sample)
lm.data01.sample <- lm(y~., data = data01.sample)
summary(lm.data01.sample)
?predict
coef(lm.data01.sample)
class(coef(lm.data01.sample)
)
coef(lm.data01.sample)[1,]
coef(lm.data01.sample)[1]
coef(lm.data01.sample)[2]
coef(lm.data01.sample)[1:5]
predict(lm.data01.sample, newdata = data02, type="response")
class(predict(lm.data01.sample, newdata = data02, type="response")
)
y <- predict(lm.data01.sample, newdata = data02, type="response")
View(data02)
data02.temp <- cbind(y,data02)
View(data02.temp)
data02.temp <- cbind(data02,y)
View(data02.temp)
?cbind
y.pred <- predict(lm.data01.sample, newdata = data02, type="response")
data02.temp <- cbind(data02,y)
View(data02.temp)
y.pred <- predict(lm.data01.sample, newdata = data02, type="response")
data02.temp <- cbind(data02,y.pred)
View(data02.temp)
